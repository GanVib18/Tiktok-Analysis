# -*- coding: utf-8 -*-
"""BUS439_TikTok_Agents.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OTAZMV2DehiAizOUdvw_sogfUbwqvYv-
"""

!pip install groq

import pandas as pd
import numpy as np
import os
from typing import Dict, Optional
import json
import google.generativeai as genai
import time
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')


class SponsoredContentAgent:
    """Base class for agents."""

    def __init__(self, api_key: str, model: str = "gemini-1.5-pro"):
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(
            model_name=model,
            generation_config={
                "temperature": 0.3,
                "response_mime_type": "application/json"
            }
        )
        self.model_name = model
        self.name = "BaseAgent"

    def _call_api(self, prompt: str, temperature: float = 0.3, max_retries: int = 3) -> Dict:
        """Unified API call with retry logic."""
        for attempt in range(max_retries):
            try:
                # Update generation config for this call
                generation_config = {
                    "temperature": temperature,
                    "response_mime_type": "application/json"
                }

                response = self.model.generate_content(
                    prompt,
                    generation_config=generation_config
                )

                return json.loads(response.text)
            except Exception as e:
                error_msg = str(e)
                if "quota" in error_msg.lower() or "rate" in error_msg.lower():
                    wait_time = 10 * (attempt + 1)
                    print(f"\n‚ö†Ô∏è  Rate limit hit. Waiting {wait_time}s...")
                    time.sleep(wait_time)
                elif attempt < max_retries - 1:
                    print(f"\n‚ö†Ô∏è  API error (attempt {attempt+1}/{max_retries}): {error_msg[:100]}")
                    time.sleep(2)
                else:
                    print(f"\n‚ùå API call failed after {max_retries} attempts: {error_msg[:100]}")
                    return {"error": error_msg}

    def _safe_str(self, value, max_len=None):
        """Handle NaN/None values."""
        if pd.isna(value) or value is None:
            return 'N/A'
        s = str(value)
        return s[:max_len] if max_len else s


class ContentEffectivenessAgent(SponsoredContentAgent):
    """Analyzes what makes the content effective or not."""

    def __init__(self, api_key: str, model: str = "gemini-1.5-pro"):
        super().__init__(api_key, model)
        self.name = "ContentEffectivenessAgent"

    def analyze(self, video_data: Dict) -> Dict:
        engagement_rate = video_data.get('engagement_rate_calculated', 0)

        prompt = f"""Analyze this sponsored TikTok video's EFFECTIVENESS.

TITLE: {self._safe_str(video_data.get('title'), 150)}
ENGAGEMENT RATE: {engagement_rate:.2f}%
VIEWS: {video_data.get('view_count', 0):,.0f}
LIKES: {video_data.get('like_count', 0):,.0f}
COMMENTS: {video_data.get('comment_count_total', 0):,.0f}

CONTENT:
Description: {self._safe_str(video_data.get('description'), 300)}
Transcript: {self._safe_str(video_data.get('transcript_text'), 1200)}

Answer these questions:
1. **Content Hook**: What's the main hook/angle? (story, humor, education, lifestyle, etc.)
2. **Sponsor Integration**: How is the brand woven in? (seamless, obvious, forced?)
3. **Authenticity Level** (1-5): Does this feel genuine or like a hard sell?
4. **Target Audience**: Who is this for?
5. **Performance Prediction**: Based on the content quality, would you expect this to perform well? Why/why not?

BE SPECIFIC. Avoid generic responses. Reference actual content.

Return ONLY valid JSON with this structure:
{{
  "content_hook": "<specific hook type>",
  "sponsor_integration_style": "<seamless/natural/obvious/forced>",
  "authenticity_score": <1-5>,
  "target_audience": "<specific demographic>",
  "expected_performance": "<high/medium/low>",
  "performance_drivers": ["<specific factor 1>", "<specific factor 2>"],
  "weaknesses": ["<specific issue 1>", "<specific issue 2>"],
  "key_insight": "<1-2 sentences on why this works or doesn't>"
}}"""

        return self._call_api(prompt, temperature=0.2)


class AudienceResponseAgent(SponsoredContentAgent):
    """Analyzes why audiences engage (or don't)."""

    def __init__(self, api_key: str, model: str = "gemini-1.5-pro"):
        super().__init__(api_key, model)
        self.name = "AudienceResponseAgent"

    def analyze(self, video_data: Dict) -> Dict:
        engagement_rate = video_data.get('engagement_rate_calculated', 0)

        prompt = f"""Analyze WHY audiences respond to this sponsored content.

PERFORMANCE: {engagement_rate:.2f}% engagement rate
TITLE: {self._safe_str(video_data.get('title'), 150)}
CONTENT: {self._safe_str(video_data.get('transcript_text'), 1200)}

Answer:
1. **Emotional Trigger**: What emotion does this evoke? (aspiration, FOMO, humor, trust, curiosity, etc.)
2. **Value Delivery**: What value does the viewer get? (entertainment, education, inspiration, deals?)
3. **Shareability** (1-5): Would people share this?
4. **Comment-Worthiness** (1-5): Would people comment?
5. **Why It Works/Fails**: The #1 reason this gets engagement or doesn't

BE SPECIFIC about the content, not generic marketing theory.

Return ONLY valid JSON with this structure:
{{
  "emotional_trigger": "<specific emotion>",
  "value_delivered": "<specific value>",
  "shareability_score": <1-5>,
  "comment_worthiness_score": <1-5>,
  "engagement_prediction": "<will_engage/might_engage/wont_engage>",
  "primary_reason": "<why this succeeds or fails with audiences>",
  "tactical_elements": ["<specific element that drives/hurts engagement>"]
}}"""

        return self._call_api(prompt, temperature=0.2)


class BrandStrategyAgent(SponsoredContentAgent):
    """Analyzes the sponsorship approach and brand positioning."""

    def __init__(self, api_key: str, model: str = "gemini-1.5-pro"):
        super().__init__(api_key, model)
        self.name = "BrandStrategyAgent"

    def analyze(self, video_data: Dict) -> Dict:
        prompt = f"""Analyze the BRAND STRATEGY in this sponsored video.

TITLE: {self._safe_str(video_data.get('title'), 150)}
CONTENT: {self._safe_str(video_data.get('transcript_text'), 1200)}
HASHTAGS: {self._safe_str(video_data.get('hashtags'), 200)}

Answer:
1. **Brand/Product**: What's being promoted?
2. **Positioning**: How is it framed? (premium, budget-friendly, innovative, lifestyle, etc.)
3. **Disclosure Transparency** (1-5): How obvious is it that this is sponsored?
4. **Integration Type**: Story-driven, tutorial, review, lifestyle showcase, or hard-sell?
5. **Strategic Approach**: What's the brand trying to achieve here?

Return ONLY valid JSON with this structure:
{{
  "brand_category": "<beauty/tech/fashion/food/fitness/other>",
  "product_being_promoted": "<specific product>",
  "positioning_approach": "<how brand is framed>",
  "transparency_score": <1-5>,
  "integration_type": "<story/tutorial/review/lifestyle/hard_sell>",
  "strategic_objective": "<awareness/conversion/education/lifestyle_association>",
  "approach_effectiveness": "<why this approach works or doesn't for this brand>"
}}"""

        return self._call_api(prompt, temperature=0.2)


class PerformanceAnalyzer:
    """Main analyzer focused purely on performance insights."""

    def __init__(self, gemini_api_key: str, model: str = "gemini-1.5-pro"):
        self.api_key = gemini_api_key
        self.model_name = model

        # Initialize model for pattern analysis
        genai.configure(api_key=gemini_api_key)
        self.model = genai.GenerativeModel(
            model_name=model,
            generation_config={
                "temperature": 0.4,
                "response_mime_type": "application/json"
            }
        )

        # Only 3 focused agents
        self.agents = {
            'effectiveness': ContentEffectivenessAgent(gemini_api_key, model),
            'audience': AudienceResponseAgent(gemini_api_key, model),
            'strategy': BrandStrategyAgent(gemini_api_key, model)
        }

        print(f"‚úì Performance Analyzer initialized")
        print(f"  - {len(self.agents)} specialized agents")
        print(f"  - Model: {model}")

    def _calculate_engagement(self, row):
        """Calculate actual engagement rate from raw data."""
        try:
            views = float(row.get('view_count', 0))
            if views <= 0:
                return 0

            likes = float(row.get('like_count', 0))
            comments = float(row.get('comment_count_total', 0))
            reposts = float(row.get('repost_count', 0))

            engagement_rate = ((likes + comments + reposts) / views) * 100
            return round(engagement_rate, 2)
        except:
            return 0

    def analyze_single_video(self, video_data: Dict) -> Dict:
        """Analyze single video."""
        # Calculate engagement first
        video_data['engagement_rate_calculated'] = self._calculate_engagement(video_data)

        agent_results = {}
        errors = []

        for agent_name, agent in self.agents.items():
            try:
                result = agent.analyze(video_data)
                if 'error' in result:
                    errors.append(f"{agent_name}: {result['error']}")
                agent_results[agent_name] = result
                time.sleep(1.5)  # Rate limiting
            except Exception as e:
                error_msg = str(e)
                errors.append(f"{agent_name}: {error_msg}")
                agent_results[agent_name] = {"error": error_msg}

        if errors:
            print(f"\n‚ö†Ô∏è  Errors in video {video_data.get('video_id')}: {'; '.join(errors)}")

        return {
            'video_id': str(video_data.get('video_id', 'unknown')),
            'title': str(video_data.get('title', 'N/A')),
            'engagement_rate': video_data['engagement_rate_calculated'],
            'views': video_data.get('view_count', 0),
            'likes': video_data.get('like_count', 0),
            'agent_analyses': agent_results,
            'has_errors': len(errors) > 0
        }

    def analyze_batch(self, df: pd.DataFrame, max_videos: Optional[int] = None,
                     checkpoint_every: int = 25, start_from: int = 0) -> tuple:
        """Analyze batch of sponsored videos with checkpointing."""
        sponsored_df = df[df['is_sponsored'] == True].copy()

        if len(sponsored_df) == 0:
            print("‚ö†Ô∏è  No sponsored videos found")
            return pd.DataFrame(), {}

        # Apply start_from offset first
        if start_from > 0:
            if start_from >= len(sponsored_df):
                print(f"‚ö†Ô∏è  start_from ({start_from}) >= total sponsored videos ({len(sponsored_df)})")
                return pd.DataFrame(), {}
            sponsored_df = sponsored_df.iloc[start_from:].copy()
            print(f"üìç Starting from video #{start_from + 1}")

        if max_videos:
            sponsored_df = sponsored_df.head(max_videos)

        print(f"\n{'='*70}")
        print(f"PERFORMANCE-FOCUSED ANALYSIS")
        print(f"{'='*70}")
        print(f"Analyzing {len(sponsored_df)} sponsored videos (#{start_from + 1} to #{start_from + len(sponsored_df)})")
        print(f"Checkpoints every {checkpoint_every} videos")
        print(f"{'='*70}\n")

        # Analyze individual videos
        results = []
        error_count = 0

        for i, (idx, row) in enumerate(tqdm(sponsored_df.iterrows(), total=len(sponsored_df), desc="Analyzing"), 1):
            try:
                analysis = self.analyze_single_video(row.to_dict())
                results.append(analysis)

                if analysis.get('has_errors', False):
                    error_count += 1

                # Save checkpoint
                if i % checkpoint_every == 0:
                    temp_df = self._format_results(results)
                    checkpoint_file = f'checkpoint_{start_from + i}.csv'
                    temp_df.to_csv(checkpoint_file, index=False)
                    print(f"\nüíæ Checkpoint saved: {checkpoint_file}")
                    print(f"   Progress: {i}/{len(sponsored_df)} videos (total: #{start_from + i})")
                    print(f"   Errors so far: {error_count}")

                time.sleep(2)  # Rate limiting between videos

            except Exception as e:
                print(f"\n‚ö†Ô∏è  Critical error on video {row.get('video_id')}: {e}")
                error_count += 1

        results_df = self._format_results(results)
        print(f"\n‚úì Analysis complete: {len(results_df)} videos ({error_count} with errors)")

        # Performance pattern analysis
        print(f"\n{'='*70}")
        print("IDENTIFYING PERFORMANCE PATTERNS")
        print(f"{'='*70}")

        insights = self._analyze_performance_patterns(results_df)
        self._print_insights(insights, results_df)

        return results_df, insights

    def _format_results(self, results: list) -> pd.DataFrame:
        """Format results into clean DataFrame."""
        formatted_data = []

        for result in results:
            aa = result.get('agent_analyses', {})

            # Effectiveness metrics
            eff = aa.get('effectiveness', {})
            aud = aa.get('audience', {})
            strat = aa.get('strategy', {})

            row = {
                'video_id': result.get('video_id'),
                'title': result.get('title'),
                'engagement_rate': result.get('engagement_rate', 0),
                'views': result.get('views', 0),
                'likes': result.get('likes', 0),

                # Content effectiveness
                'content_hook': eff.get('content_hook', 'unknown'),
                'integration_style': eff.get('sponsor_integration_style', 'unknown'),
                'authenticity_score': eff.get('authenticity_score', 3),
                'expected_performance': eff.get('expected_performance', 'unknown'),
                'performance_drivers': ', '.join(eff.get('performance_drivers', [])),
                'weaknesses': ', '.join(eff.get('weaknesses', [])),
                'effectiveness_insight': eff.get('key_insight', ''),

                # Audience response
                'emotional_trigger': aud.get('emotional_trigger', 'unknown'),
                'value_delivered': aud.get('value_delivered', 'unknown'),
                'shareability_score': aud.get('shareability_score', 3),
                'engagement_prediction': aud.get('engagement_prediction', 'unknown'),
                'audience_reason': aud.get('primary_reason', ''),

                # Brand strategy
                'brand_category': strat.get('brand_category', 'unknown'),
                'product': strat.get('product_being_promoted', 'unknown'),
                'positioning': strat.get('positioning_approach', 'unknown'),
                'integration_type': strat.get('integration_type', 'unknown'),
                'strategic_objective': strat.get('strategic_objective', 'unknown'),
            }
            formatted_data.append(row)

        return pd.DataFrame(formatted_data)

    def _analyze_performance_patterns(self, results_df: pd.DataFrame) -> Dict:
        """Identify what separates high from low performers."""
        if len(results_df) < 5:
            return {"error": "Need at least 5 videos for pattern analysis"}

        # Segment by performance
        results_df['engagement_rate'] = pd.to_numeric(results_df['engagement_rate'], errors='coerce').fillna(0)

        top_quartile = results_df.nlargest(max(3, int(len(results_df) * 0.25)), 'engagement_rate')
        bottom_quartile = results_df.nsmallest(max(3, int(len(results_df) * 0.25)), 'engagement_rate')

        # Build comparative summary
        def summarize_segment(df, segment_name):
            return {
                'count': len(df),
                'avg_engagement': df['engagement_rate'].mean(),
                'top_hooks': df['content_hook'].value_counts().head(3).to_dict(),
                'top_integration_styles': df['integration_style'].value_counts().head(3).to_dict(),
                'avg_authenticity': df['authenticity_score'].mean(),
                'top_emotional_triggers': df['emotional_trigger'].value_counts().head(3).to_dict(),
                'top_integration_types': df['integration_type'].value_counts().head(3).to_dict(),
                'example_titles': df['title'].head(3).tolist(),
            }

        top_summary = summarize_segment(top_quartile, "Top Performers")
        bottom_summary = summarize_segment(bottom_quartile, "Bottom Performers")

        # Ask LLM to analyze the patterns
        prompt = f"""Analyze what separates HIGH vs LOW performing sponsored TikTok videos.

TOP 25% PERFORMERS:
{json.dumps(top_summary, indent=2)}

BOTTOM 25% PERFORMERS:
{json.dumps(bottom_summary, indent=2)}

Provide actionable insights.

Return ONLY valid JSON with this structure:
{{
  "key_differentiators": ["<Top 3 factors that separate winners from losers>"],
  "winning_characteristics": ["<What high performers consistently do>"],
  "losing_mistakes": ["<What low performers consistently do wrong>"],
  "best_content_hook": "<Which hook type performs best>",
  "best_integration_style": "<Which integration works best>",
  "best_emotional_trigger": "<Which emotion drives most engagement>",
  "authenticity_impact": "<Does higher authenticity = better performance? Yes/No/Mixed>",
  "success_formula": "<The proven pattern for high engagement>",
  "avoid_these": ["<Specific things to avoid>"],
  "actionable_playbook": "<3-4 sentence guide: if you're creating sponsored content tomorrow, do THIS>"
}}"""

        try:
            response = self.model.generate_content(prompt)
            llm_insights = json.loads(response.text)
        except Exception as e:
            print(f"‚ö†Ô∏è  Pattern analysis error: {e}")
            llm_insights = {"error": "Failed to generate insights"}

        return {
            'top_performers': top_summary,
            'bottom_performers': bottom_summary,
            'insights': llm_insights
        }

    def _print_insights(self, insights: Dict, results_df: pd.DataFrame):
        """Print actionable performance insights."""
        llm = insights.get('insights', {})

        print(f"\n{'='*70}")
        print("üéØ WHAT MAKES SPONSORED VIDEOS PERFORM WELL")
        print(f"{'='*70}")

        if 'key_differentiators' in llm:
            print("\nüìä KEY DIFFERENTIATORS (Winners vs Losers):")
            for diff in llm['key_differentiators']:
                print(f"  ‚Ä¢ {diff}")

        if 'winning_characteristics' in llm:
            print("\n‚úÖ WHAT HIGH PERFORMERS DO:")
            for char in llm['winning_characteristics']:
                print(f"  ‚Ä¢ {char}")

        if 'losing_mistakes' in llm:
            print("\n‚ùå WHAT LOW PERFORMERS DO WRONG:")
            for mistake in llm['losing_mistakes']:
                print(f"  ‚Ä¢ {mistake}")

        if 'success_formula' in llm:
            print(f"\nüèÜ SUCCESS FORMULA:")
            print(f"  {llm['success_formula']}")

        if 'actionable_playbook' in llm:
            print(f"\nüí° ACTIONABLE PLAYBOOK:")
            print(f"  {llm['actionable_playbook']}")

        print(f"\n{'='*70}")
        print("üìà PERFORMANCE BREAKDOWN")
        print(f"{'='*70}")

        top = insights.get('top_performers', {})
        bottom = insights.get('bottom_performers', {})

        print(f"\nTop 25%: {top.get('avg_engagement', 0):.2f}% avg engagement")
        print(f"Bottom 25%: {bottom.get('avg_engagement', 0):.2f}% avg engagement")
        print(f"Delta: {top.get('avg_engagement', 0) - bottom.get('avg_engagement', 0):.2f}% difference")

        print(f"\n{'='*70}\n")


def analyze_sponsored_content(csv_path: str,
                              gemini_api_key: str,
                              max_videos: Optional[int] = 50,
                              output_path: Optional[str] = None,
                              model: str = "gemini-1.5-pro",
                              start_from: int = 0):
    """
    Analyze sponsored content for performance patterns.

    Focus: What makes videos perform well?

    Args:
        csv_path: Path to CSV file with TikTok data
        gemini_api_key: Your Google Gemini API key
        max_videos: Max number of videos to analyze
        output_path: Where to save results
        model: Gemini model to use (gemini-1.5-pro, gemini-1.5-flash, gemini-2.0-flash-exp)
        start_from: Start from this video number (0-indexed, use 83 to continue from video #84)
    """
    print(f"Loading: {csv_path}")
    df = pd.read_csv(csv_path)
    print(f"‚úì Loaded {len(df):,} videos ({df['is_sponsored'].sum():,} sponsored)")

    analyzer = PerformanceAnalyzer(gemini_api_key, model=model)
    results_df, insights = analyzer.analyze_batch(df, max_videos=max_videos, start_from=start_from)

    if output_path and len(results_df) > 0:
        results_df.to_csv(output_path, index=False)

        insights_path = output_path.replace('.csv', '_insights.json')
        with open(insights_path, 'w') as f:
            json.dump(insights, f, indent=2)

        print(f"‚úì Results: {output_path}")
        print(f"‚úì Insights: {insights_path}")

    return results_df, insights, analyzer


if __name__ == "__main__":
    # Get your API key from: https://aistudio.google.com/apikey
    GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "enter-your-api-key-here")

    # DAY 1: Process videos 1-83 (already done)
    # DAY 2: Process videos 84-163 (uncomment below)
    # DAY 3: Process videos 164-175 (uncomment below)
    results_df, insights, analyzer = analyze_sponsored_content(
        csv_path='tiktok_data_analyzed.csv',
        gemini_api_key=GEMINI_API_KEY,
        max_videos=20,
        output_path='performance_analysis_batch3.csv',
        model="gemini-2.5-flash",
        start_from=163  # Start from video #164
    )

    # Show results
    print("\nTop performers:")
    print(results_df.nlargest(5, 'engagement_rate')[
        ['title', 'engagement_rate', 'content_hook', 'integration_style', 'emotional_trigger']
    ])

