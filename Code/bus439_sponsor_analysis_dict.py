# -*- coding: utf-8 -*-
"""BUS439_sponsor_analysis_dict.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XB-UUJzOztW9ZxNu9E1Iu8eLf6iuhEQ2
"""

pip install nltk textstat vaderSentiment empath

import pandas as pd
import numpy as np
import statsmodels.api as sm
import statsmodels.formula.api as smf
from scipy.stats import ttest_ind, zscore
from empath import Empath
import nltk
nltk.download('vader_lexicon')
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import textstat
import re
from datetime import datetime
import warnings

# Suppress convergence warnings for cleaner output
warnings.filterwarnings("ignore")

df = pd.read_csv('/content/tiktok_data_analyzed.csv')

# Initialize Analyzers
lexicon = Empath()
vader = SentimentIntensityAnalyzer()

# ==========================================
# ðŸŽ¯ PHASE 1: DATA PREPARATION
# ==========================================
def run_phase_1_data_prep(df):
    print("\n--- PHASE 1: DATA PREPARATION ---")

    # [cite_start]1.1 Load & Clean [cite: 31-42]
    initial_count = len(df)
    df = df.dropna(subset=['description']).copy()
    print(f"Dropped {initial_count - len(df)} rows with missing descriptions.")

    # [cite_start]1.2 Identify Sponsored [cite: 19-30]
    # (Assuming 'is_sponsored' exists as per your column list, ensuring it's integer)
    df['is_sponsored'] = df['is_sponsored'].astype(int)

    # [cite_start]1.3 Handle Dates & Engagement [cite: 43-46]
    # Try multiple date formats
    try:
        df['dt_date'] = pd.to_datetime(df['upload_date'], format='%Y%m%d', errors='coerce')
    except:
        df['dt_date'] = pd.to_datetime(df['upload_date'], errors='coerce')

    # Engagement Rate = (Likes + Comments) / Views
    df['engagement_rate'] = (df['like_count'] + df['comment_count_total'] + df['repost_count']) / (df['view_count'] + 1)

    print(f"Data ready: {len(df)} videos across {df['uploader'].nunique()} creators.")
    return df

# ==========================================
# ðŸŽ¯ PHASE 2: FEATURE EXTRACTION (WITH EMPATH)
# ==========================================
def run_phase_2_feature_extraction(df):
    print("\n--- PHASE 2: FEATURE EXTRACTION (EMPATH POWERED) ---")

    # [cite_start]define Empath categories to aggregate [cite: 75]
    # Commercial Focus (Negative Authenticity Drivers)
    cats_commercial = ['money', 'business', 'shopping', 'payment', 'work', 'economics']
    # Authentic Warmth (Positive Authenticity Drivers)
    cats_warmth = ['warmth', 'family', 'friends', 'positive_emotion', 'trust', 'love']

    # Define structural proxies (Empath might miss specific TikTok slang)
    tiktok_commercial_slang = ['link in bio', 'use code', 'discount', '#ad', 'partner']

    features = []

    for _, row in df.iterrows():
        text = str(row['description'])

        # [cite_start]A. Structural Features [cite: 66]
        word_count = len(text.split())

        # [cite_start]B. Sentiment (VADER) [cite: 67]
        sentiment = vader.polarity_scores(text)['compound']

        # [cite_start]C. Readability (Flesch) [cite: 68]
        if word_count > 3:
            try:
                readability = textstat.flesch_reading_ease(text)
            except:
                readability = 50
        else:
            readability = 100

        # [cite_start]D. Pronouns (First/Second Person) [cite: 69]
        # Regex for "I, me, my" vs "You, your"
        fp_count = len(re.findall(r'\b(i|me|my|mine|myself)\b', text.lower()))
        sp_count = len(re.findall(r'\b(you|your|yours|yourself)\b', text.lower()))

        # [cite_start]E. EMPATH ANALYSIS (The core update) [cite: 75]
        # analyze() returns a dict of counts
        empath_res = lexicon.analyze(text, categories=cats_commercial + cats_warmth, normalize=False)

        if empath_res:
            emp_comm_score = sum(empath_res[c] for c in cats_commercial)
            emp_warmth_score = sum(empath_res[c] for c in cats_warmth)
        else:
            emp_comm_score = 0
            emp_warmth_score = 0

        # Add manual commercial slang to Empath score
        slang_hits = sum(1 for s in tiktok_commercial_slang if s in text.lower())
        emp_comm_score += slang_hits

        # Store row
        features.append({
            'desc_word_count': word_count,
            'desc_sentiment': sentiment,
            'desc_readability': readability,
            'desc_first_person_pct': (fp_count / (word_count+1)) * 100,
            'desc_second_person_pct': (sp_count / (word_count+1)) * 100,
            'desc_empath_commercial': emp_comm_score,
            'desc_empath_warmth': emp_warmth_score
        })

    # Merge features back
    feat_df = pd.DataFrame(features)
    df = pd.concat([df.reset_index(drop=True), feat_df], axis=1)

    # [cite_start]2.2 Create Authenticity Score [cite: 81-100]
    print("Calculating Composite Authenticity Score...")

    # Z-Score Normalization Helper
    def get_z(col):
        if col.std() == 0: return col * 0
        return (col - col.mean()) / col.std()

    # Positive Indicators: First Person, Warmth (Empath), Sentiment, Readability
    z_pos = (get_z(df['desc_first_person_pct']) +
             get_z(df['desc_empath_warmth']) +
             get_z(df['desc_sentiment']) +
             get_z(df['desc_readability']))

    # Negative Indicators: Commercial Focus (Empath + Slang)
    z_neg = get_z(df['desc_empath_commercial']) * -1 # Reverse code

    # Composite (Average of 5 components)
    df['authenticity_raw'] = (z_pos + z_neg) / 5

    # Scale 0-100
    df['authenticity_score'] = ((df['authenticity_raw'] - df['authenticity_raw'].min()) /
                               (df['authenticity_raw'].max() - df['authenticity_raw'].min())) * 100

    return df

# ==========================================
# ðŸŽ¯ PHASE 3: MATCHING STRATEGY
# ==========================================
def run_phase_3_matching(df):
    print("\n--- PHASE 3: MATCHING (TEMPORAL) ---")
    # [cite_start]Strategy: For every sponsored video, find 3 organic videos from SAME creator CLOSEST in time [cite: 130-132]

    matches = []
    sponsored_subset = df[df['is_sponsored'] == 1]
    organic_subset = df[df['is_sponsored'] == 0]

    for idx, sp_row in sponsored_subset.iterrows():
        # Filter for same creator
        candidates = organic_subset[organic_subset['uploader'] == sp_row['uploader']].copy()

        if candidates.empty:
            continue

        # Calculate time distance
        candidates['days_diff'] = (candidates['dt_date'] - sp_row['dt_date']).abs().dt.days

        # Pick top 3 matches
        best_matches = candidates.sort_values('days_diff').head(3)

        # Add Sponsored Row
        matches.append(sp_row.to_dict())

        # Add Organic Rows (mark them with the sponsored group ID)
        for _, org_row in best_matches.iterrows():
            r = org_row.to_dict()
            r['match_group_id'] = sp_row['video_id'] # Track which sponsored video this belongs to
            matches.append(r)

    matched_df = pd.DataFrame(matches)
    print(f"Matched Dataset Created: {len(matched_df)} rows (1 Sponsored : ~3 Organic).")
    return matched_df

# ==========================================
# ðŸŽ¯ PHASE 4: DESCRIPTIVE ANALYSIS
# ==========================================
def run_phase_4_statistics(df):
    print("\n--- PHASE 4: DESCRIPTIVE STATISTICS ---")

    # [cite_start]4.1 Summary Table [cite: 176-185]
    cols = ['authenticity_score', 'desc_empath_commercial', 'desc_empath_warmth', 'desc_first_person_pct']
    summary = df.groupby('is_sponsored')[cols].agg(['mean', 'std'])
    print(summary)

    # [cite_start]4.2 Significance Testing [cite: 196-205]
    sp = df[df['is_sponsored']==1]['authenticity_score']
    org = df[df['is_sponsored']==0]['authenticity_score']

    t_stat, p_val = ttest_ind(sp, org, equal_var=False)
    print(f"\n[T-Test] Authenticity Score Difference: t={t_stat:.3f}, p={p_val:.5f}")
    if p_val < 0.05:
        print(">> RESULT: Significant drop in authenticity detected.")
    else:
        print(">> RESULT: No significant difference detected.")

# ==========================================
# ðŸŽ¯ PHASE 5: REGRESSION ANALYSIS
# ==========================================
def run_phase_5_regression(matched_df):
    print("\n--- PHASE 5: REGRESSION ANALYSIS ---")

    # Standardize predictors for convergence
    matched_df['z_followers'] = zscore(np.log(matched_df['follower_count'] + 1))
    matched_df['z_word_count'] = zscore(matched_df['desc_word_count'])

    # [cite_start]5.1 Main Effects (Mixed Model) [cite: 253-272]
    # We use a Mixed Linear Model to account for Creator clustering
    print("\n[Model 5.1] Main Effect of Sponsorship on Authenticity")
    md = smf.mixedlm("authenticity_score ~ is_sponsored + z_word_count",
                     matched_df,
                     groups=matched_df["uploader"])
    mdf = md.fit()
    print(mdf.summary())

    # [cite_start]5.2 Moderation Analysis (Creator Size) [cite: 273-293]
    print("\n[Model 5.2] Does Creator Size Moderate the Authenticity Drop?")
    md_int = smf.mixedlm("authenticity_score ~ is_sponsored * z_followers",
                         matched_df,
                         groups=matched_df["uploader"])
    mdf_int = md_int.fit()
    print(mdf_int.summary())

    # [cite_start]5.3 Engagement Consequences [cite: 294-312]
    # Run ONLY on Sponsored videos
    print("\n[Model 5.3] Does Authenticity Drive Engagement in Sponsored Videos?")
    sponsored_only = matched_df[matched_df['is_sponsored'] == 1].copy()

    # Log transform engagement (highly skewed)
    sponsored_only['log_engagement'] = np.log(sponsored_only['engagement_rate'] + 0.00001)
    sponsored_only['z_auth'] = zscore(sponsored_only['authenticity_score'])

    # OLS is sufficient here as we are looking within the sponsored subset
    res_eng = smf.ols("log_engagement ~ z_auth + z_followers + z_word_count", data=sponsored_only).fit()
    print(res_eng.summary())

# ==========================================
# ðŸš€ EXECUTION BLOCK
# ==========================================
# Assuming your initial dataframe is named 'df'

# Phase 1
df_clean = run_phase_1_data_prep(df)

# Phase 2 (Empath)
df_features = run_phase_2_feature_extraction(df_clean)

# Phase 3
df_matched = run_phase_3_matching(df_features)

# Phase 4
run_phase_4_statistics(df_matched)

# Phase 5
run_phase_5_regression(df_matched)

print("\n--- Analysis Complete ---")

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

# Set style for publication-quality plots
sns.set_style("whitegrid")
plt.rcParams.update({'font.size': 12})

def create_publication_figures(matched_df, full_df):
    print("--- Generatng Phase 7.2 Visualizations ---")

    # FIGURE 1: The Authenticity Gap (Boxplot) [cite: 891]
    # Shows the distribution drop from Organic to Sponsored
    plt.figure(figsize=(8, 6))
    # [Image of boxplot comparison]

    ax = sns.boxplot(x='is_sponsored', y='authenticity_score', data=matched_df,
                     palette=['#3498db', '#e74c3c'], showfliers=False)
    plt.xticks([0, 1], ['Organic Content', 'Sponsored Content'])
    plt.ylabel('Authenticity Score (0-100)')
    plt.title('Figure 1: The Effect of Sponsorship on Linguistic Authenticity')

    # Add mean markers
    means = matched_df.groupby('is_sponsored')['authenticity_score'].mean()
    plt.plot([0, 1], means.values, 'ko--', linewidth=1, label='Mean')
    plt.legend()
    plt.tight_layout()
    plt.show()

    # FIGURE 2: Where the Authenticity Goes (Feature Comparison) [cite: 895]
    # Comparing the raw feature shifts
    features = ['desc_first_person_pct', 'desc_empath_commercial', 'desc_empath_warmth']
    feature_names = ['First Person % ("I/Me")', 'Commercial Terms (Count)', 'Warmth Terms (Count)']

    # Normalize features for side-by-side comparison (Z-score relative to global mean)
    plot_data = matched_df.copy()
    for f in features:
        plot_data[f] = (plot_data[f] - plot_data[f].mean()) / plot_data[f].std()

    long_df = pd.melt(plot_data, id_vars=['is_sponsored'], value_vars=features,
                      var_name='Feature', value_name='Z-Score')

    plt.figure(figsize=(10, 6))
    # [Image of grouped bar chart]

    sns.barplot(x='Feature', y='Z-Score', hue='is_sponsored', data=long_df, palette=['#3498db', '#e74c3c'])
    plt.xticks(ticks=[0, 1, 2], labels=feature_names)
    plt.axhline(0, color='black', linewidth=0.5)
    plt.ylabel('Standardized Score (Z-Score)')
    plt.title('Figure 2: Shift in Linguistic Features (Standardized)')
    plt.legend(['Organic', 'Sponsored'])
    plt.tight_layout()
    plt.show()

    # FIGURE 3: The "Big Creator" Trap (Interaction Plot)
    # Visualizing Model 5.2 (Follower count moderation)
    plt.figure(figsize=(10, 6))

    # --- STEP 1: Create the Tiers ---
    # Define the conditions for the tiers
    conditions = [
        matched_df['follower_count'] > 1000000,  # High Tier
        (matched_df['follower_count'] >= 100000) & (matched_df['follower_count'] <= 1000000), # Medium Tier
        matched_df['follower_count'] < 100000   # Low Tier
    ]

    # Define the labels corresponding to the conditions
    choices = ['High Tier (>1M)', 'Medium Tier (100k-1M)', 'Low Tier (<100k)']

    # Create the new column
    matched_df['Creator Tier'] = np.select(conditions, choices, default='Unknown')

    # --- STEP 2: Visualization ---

    # Define the order so the legend appears logically (Low -> Med -> High)
    tier_order = ['Low Tier (<100k)', 'Medium Tier (100k-1M)', 'High Tier (>1M)']

    # Define specific colors for each tier
    # High -> Red, Medium -> Blue, Low -> Green
    custom_palette = {
        'High Tier (>1M)': 'red',
        'Medium Tier (100k-1M)': 'blue',
        'Low Tier (<100k)': 'green'
    }

    sns.pointplot(
        x='is_sponsored',
        y='authenticity_score',
        hue='Creator Tier',
        data=matched_df,
        hue_order=tier_order,         # Enforce logical ordering
        markers=['o', 's', '^'],      # Added a 3rd marker (Triangle) for the 3rd category
        linestyles=['-', '--', ':'],  # Optional: Different line styles for accessibility
        capsize=0.1,
        palette=custom_palette
    )

    plt.xticks([0, 1], ['Organic', 'Sponsored'])
    plt.ylabel('Authenticity Score')
    plt.title('Figure 3: Moderation Effect by Creator Tier (High vs. Medium vs. Low)')
    plt.legend(title='Creator Tier')
    plt.tight_layout()
    plt.show()

    # FIGURE 4: Authenticity Pays Off (Engagement Regression) [cite: 904]
    # Visualizing Model 5.3 (Sponsored videos only)
    sponsored_only = matched_df[matched_df['is_sponsored'] == 1]

    plt.figure(figsize=(8, 6))
    # [Image of scatter plot with regression line]

    sns.regplot(x='authenticity_score', y='engagement_rate', data=sponsored_only,
                scatter_kws={'alpha':0.5}, line_kws={'color':'red'})

    plt.xlabel('Authenticity Score')
    plt.ylabel('Engagement Rate')
    plt.title('Figure 4: Authenticity vs. Engagement (Sponsored Videos Only)')
    plt.tight_layout()
    plt.show()

def extract_qualitative_cases(df):
    print("\n--- Phase 6: Qualitative Validation (Case Extraction) ---")
    # [cite: 803-820]

    sponsored = df[df['is_sponsored'] == 1].copy()

    # 1. High Authenticity Sponsored (The "Good" Ads)
    top_auth = sponsored.nlargest(3, 'authenticity_score')

    # 2. Low Authenticity Sponsored (The "Bad" Ads)
    bot_auth = sponsored.nsmallest(3, 'authenticity_score')

    print("\n>>> CASE STUDY: HIGH AUTHENTICITY SPONSORED ADS <<<")
    for i, row in top_auth.iterrows():
        print(f"\n[Score: {row['authenticity_score']:.1f} | Views: {row['view_count']}]")
        print(f"Desc: {str(row['description'])[:300]}...") # Print first 300 chars

    print("\n>>> CASE STUDY: LOW AUTHENTICITY SPONSORED ADS <<<")
    for i, row in bot_auth.iterrows():
        print(f"\n[Score: {row['authenticity_score']:.1f} | Views: {row['view_count']}]")
        print(f"Desc: {str(row['description'])[:300]}...")

# Execute
# Use the dataframes from your previous run (df_matched, df_features)
create_publication_figures(df_matched, df_features)
extract_qualitative_cases(df_features)

# ==========================================
# ðŸŽ¯ PHASE 5: IMPROVED REGRESSION ANALYSIS
# ==========================================

def run_phase_5_regression_improved(matched_df):
    print("\n--- PHASE 5: REGRESSION ANALYSIS (IMPROVED) ---")

    # ============================================
    # PREPARATION: Better Scaling & Centering
    # ============================================

    # 1. Center and scale ALL predictors properly
    # Center follower count at the MEDIAN (more robust than mean)
    matched_df['followers_centered'] = matched_df['follower_count'] - matched_df['follower_count'].median()
    matched_df['z_followers'] = zscore(np.log(matched_df['follower_count'] + 1))
    matched_df['z_word_count'] = zscore(matched_df['desc_word_count'])

    # 2. Create group-mean centered predictors (helps with convergence)
    matched_df['z_followers_gmc'] = matched_df.groupby('uploader')['z_followers'].transform(
        lambda x: x - x.mean()
    )

    # 3. Filter out creators with very few observations (can cause instability)
    creator_counts = matched_df['uploader'].value_counts()
    valid_creators = creator_counts[creator_counts >= 4].index
    matched_df_filtered = matched_df[matched_df['uploader'].isin(valid_creators)].copy()

    print(f"Filtered to {len(matched_df_filtered)} observations across {len(valid_creators)} creators")
    print(f"(Removed creators with <4 observations)")

    # ============================================
    # MODEL 5.1: Main Effects with Convergence Fixes
    # ============================================
    print("\n[Model 5.1] Main Effect - Multiple Convergence Strategies")

    # STRATEGY 1: Increase iterations + better method
    try:
        md = smf.mixedlm(
            "authenticity_score ~ is_sponsored + z_word_count",
            matched_df_filtered,
            groups=matched_df_filtered["uploader"]
        )
        mdf = md.fit(maxiter=500, method='lbfgs')  # Increased iterations + LBFGS optimizer

        if mdf.converged:
            print("âœ“ CONVERGED with LBFGS method")
            print(mdf.summary())
        else:
            print("âœ— Did not converge with LBFGS, trying Powell...")
            raise Exception("Force Powell method")

    except:
        # STRATEGY 2: Try Powell method (more robust but slower)
        md = smf.mixedlm(
            "authenticity_score ~ is_sponsored + z_word_count",
            matched_df_filtered,
            groups=matched_df_filtered["uploader"]
        )
        mdf = md.fit(method='powell', maxiter=1000)

        if mdf.converged:
            print("âœ“ CONVERGED with Powell method")
        else:
            print("âš  Still not converged - see alternative approaches below")

        print(mdf.summary())

    # ============================================
    # MODEL 5.2: Moderation with Multiple Fixes
    # ============================================
    print("\n[Model 5.2] Moderation Effect - Advanced Convergence Techniques")

    # APPROACH A: Standard with better parameters
    print("\n--- Approach A: Optimized Standard Model ---")
    try:
        md_int = smf.mixedlm(
            "authenticity_score ~ is_sponsored * z_followers + z_word_count",
            matched_df_filtered,
            groups=matched_df_filtered["uploader"]
        )

        # Try multiple optimizers in sequence
        for method in ['lbfgs', 'powell', 'cg']:
            print(f"Trying {method}...")
            mdf_int = md_int.fit(method=method, maxiter=1000, reml=True)

            if mdf_int.converged:
                print(f"âœ“ CONVERGED with {method}")
                break

        print(mdf_int.summary())

    except Exception as e:
        print(f"Standard approach failed: {e}")

    # APPROACH B: Simpler random effects structure
    print("\n--- Approach B: Random Intercept Only (Simplified) ---")
    try:
        md_simple = smf.mixedlm(
            "authenticity_score ~ is_sponsored * z_followers + z_word_count",
            matched_df_filtered,
            groups=matched_df_filtered["uploader"],
            # No random slopes - only random intercepts
        )
        mdf_simple = md_simple.fit(method='powell', maxiter=1000)

        print(f"Converged: {mdf_simple.converged}")
        print(mdf_simple.summary())

    except Exception as e:
        print(f"Simplified approach failed: {e}")

    # APPROACH C: Group-mean centering (often fixes convergence)
    print("\n--- Approach C: Group-Mean Centered Predictors ---")
    try:
        md_gmc = smf.mixedlm(
            "authenticity_score ~ is_sponsored * z_followers_gmc + z_word_count",
            matched_df_filtered,
            groups=matched_df_filtered["uploader"]
        )
        mdf_gmc = md_gmc.fit(method='lbfgs', maxiter=1000)

        print(f"Converged: {mdf_gmc.converged}")
        print(mdf_gmc.summary())

    except Exception as e:
        print(f"GMC approach failed: {e}")

    # APPROACH D: Robust alternative - Fixed Effects
    print("\n--- Approach D: Fixed Effects Model (Robust Alternative) ---")
    try:
        from linearmodels.panel import PanelOLS

        # Reshape for panel structure
        matched_df_filtered['creator_id'] = pd.Categorical(matched_df_filtered['uploader']).codes
        matched_df_filtered = matched_df_filtered.set_index(['creator_id', 'video_id'])

        fe_model = PanelOLS.from_formula(
            'authenticity_score ~ is_sponsored * z_followers + z_word_count + EntityEffects',
            data=matched_df_filtered
        )
        fe_results = fe_model.fit(cov_type='clustered', cluster_entity=True)

        print("âœ“ Fixed Effects Model (always converges)")
        print(fe_results.summary)

    except ImportError:
        print("Install linearmodels: pip install linearmodels")
    except Exception as e:
        print(f"Fixed effects failed: {e}")

    # ============================================
    # MODEL 5.3: Engagement (Usually converges fine)
    # ============================================
    print("\n[Model 5.3] Engagement Consequences")
    sponsored_only = matched_df_filtered[matched_df_filtered['is_sponsored'] == 1].copy()

    # Remove extreme outliers in engagement
    sponsored_only = sponsored_only[
        (sponsored_only['engagement_rate'] > 0) &
        (sponsored_only['engagement_rate'] < sponsored_only['engagement_rate'].quantile(0.99))
    ]

    sponsored_only['log_engagement'] = np.log(sponsored_only['engagement_rate'] + 0.00001)
    sponsored_only['z_auth'] = zscore(sponsored_only['authenticity_score'])

    res_eng = smf.ols(
        "log_engagement ~ z_auth + z_followers + z_word_count",
        data=sponsored_only
    ).fit(cov_type='HC3')  # Robust standard errors

    print(res_eng.summary())

    # ============================================
    # DIAGNOSTIC OUTPUT
    # ============================================
    print("\n--- Convergence Diagnostics ---")
    print(f"Final sample size: {len(matched_df_filtered)}")
    print(f"Number of groups: {matched_df_filtered['uploader'].nunique()}")
    print(f"Group size range: {matched_df_filtered.groupby('uploader').size().min()} to {matched_df_filtered.groupby('uploader').size().max()}")
    print(f"Predictor correlations:")
    print(matched_df_filtered[['is_sponsored', 'z_followers', 'z_word_count']].corr())

    return matched_df_filtered


# ============================================
# BONUS: Visualization of Convergence
# ============================================

def diagnose_convergence_issues(matched_df):
    """
    Visual diagnostics to understand why models might not converge
    """
    import matplotlib.pyplot as plt
    import seaborn as sns

    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # 1. Group size distribution
    group_sizes = matched_df.groupby('uploader').size()
    axes[0, 0].hist(group_sizes, bins=20, edgecolor='black')
    axes[0, 0].set_xlabel('Observations per Creator')
    axes[0, 0].set_ylabel('Frequency')
    axes[0, 0].set_title('Distribution of Group Sizes')
    axes[0, 0].axvline(4, color='red', linestyle='--', label='Min threshold')
    axes[0, 0].legend()

    # 2. Outcome distribution by group
    sns.boxplot(data=matched_df, x='is_sponsored', y='authenticity_score', ax=axes[0, 1])
    axes[0, 1].set_title('Outcome Distribution')

    # 3. Predictor correlation
    corr = matched_df[['is_sponsored', 'follower_count', 'desc_word_count', 'authenticity_score']].corr()
    sns.heatmap(corr, annot=True, cmap='coolwarm', center=0, ax=axes[1, 0])
    axes[1, 0].set_title('Predictor Correlations')

    # 4. Variance by group
    group_vars = matched_df.groupby('uploader')['authenticity_score'].var()
    axes[1, 1].hist(group_vars.dropna(), bins=20, edgecolor='black')
    axes[1, 1].set_xlabel('Within-Creator Variance')
    axes[1, 1].set_ylabel('Frequency')
    axes[1, 1].set_title('Heterogeneity Across Creators')

    plt.tight_layout()
    plt.show()

    print("\n--- Issue Detection ---")
    print(f"Creators with <4 obs: {(group_sizes < 4).sum()}")
    print(f"Creators with zero variance: {(group_vars == 0).sum()}")
    print(f"Max correlation between predictors: {corr.abs().where(~np.eye(len(corr), dtype=bool)).max().max():.3f}")


# ============================================
# EXECUTION
# ============================================

# Run diagnostics first
diagnose_convergence_issues(df_matched)

# Run improved regression
df_final = run_phase_5_regression_improved(df_matched)

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

# Set publication-quality style
sns.set_style("whitegrid")
plt.rcParams.update({
    'font.size': 12,
    'font.family': 'sans-serif',
    'axes.labelsize': 13,
    'axes.titlesize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 11
})

def create_moderation_figure(matched_df):
    """
    Create the moderation effect visualization based on Approach B results
    Uses the converged model parameters: Î²0=39.037, Î²1=-5.829, Î²2=2.374, Î²3=-4.190
    """

    # ============================================
    # FIGURE 3A: Predicted Values from Model
    # ============================================
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))

    # Extract model coefficients from Approach B
    intercept = 39.037
    beta_sponsored = -5.829
    beta_followers = 2.374
    beta_interaction = -4.190

    # Create three follower levels (Low, Medium, High)
    # Using -1 SD, Mean, +1 SD
    follower_levels = {
        'Low Tier (<100k)': -1.0,
        'Medium Tier (100k-1M)': 0.0,
        'High Tier (>1M)': 1.0
    }

    # Calculate predicted values
    predictions = []
    for tier_name, z_followers in follower_levels.items():
        # Organic content (is_sponsored = 0)
        auth_organic = intercept + beta_followers * z_followers

        # Sponsored content (is_sponsored = 1)
        auth_sponsored = (intercept +
                         beta_sponsored +
                         beta_followers * z_followers +
                         beta_interaction * z_followers)

        predictions.append({
            'Tier': tier_name,
            'Organic': auth_organic,
            'Sponsored': auth_sponsored,
            'Drop': auth_organic - auth_sponsored
        })

    pred_df = pd.DataFrame(predictions)

    # PLOT 1: Line plot showing interaction
    ax1 = axes[0]

    colors = {'High Tier (>1M)': '#e74c3c',
              'Medium Tier (100k-1M)': '#3498db',
              'Low Tier (<100k)': '#2ecc71'}

    markers = {'High Tier (>1M)': '^',
               'Medium Tier (100k-1M)': 's',
               'Low Tier (<100k)': 'o'}

    for tier in ['Low Tier (<100k)', 'Medium Tier (100k-1M)', 'High Tier (>1M)']:
        row = pred_df[pred_df['Tier'] == tier].iloc[0]
        ax1.plot([0, 1], [row['Organic'], row['Sponsored']],
                marker=markers[tier], markersize=10, linewidth=2.5,
                color=colors[tier], label=tier)

    ax1.set_xticks([0, 1])
    ax1.set_xticklabels(['Organic', 'Sponsored'], fontsize=13)
    ax1.set_ylabel('Predicted Authenticity Score', fontsize=13)
    ax1.set_title('(A) Moderation Effect: Creator Size Ã— Sponsorship',
                  fontsize=14, fontweight='bold')
    ax1.legend(title='Creator Tier', loc='best', frameon=True)
    ax1.grid(True, alpha=0.3)
    ax1.set_ylim(30, 48)

    # Add annotation for the steepest drop
    ax1.annotate('', xy=(1, pred_df.iloc[2]['Sponsored']),
                xytext=(0, pred_df.iloc[2]['Organic']),
                arrowprops=dict(arrowstyle='<->', color='red', lw=2, alpha=0.5))
    ax1.text(0.5, pred_df.iloc[2]['Organic'] - 3,
            f"Drop: {pred_df.iloc[2]['Drop']:.1f} pts",
            ha='center', color='red', fontsize=10, fontweight='bold')

    # PLOT 2: Bar chart showing the drop magnitude
    ax2 = axes[1]

    tiers_ordered = ['Low Tier (<100k)', 'Medium Tier (100k-1M)', 'High Tier (>1M)']
    drops = [pred_df[pred_df['Tier']==t]['Drop'].values[0] for t in tiers_ordered]
    colors_ordered = [colors[t] for t in tiers_ordered]

    bars = ax2.bar(range(len(tiers_ordered)), drops, color=colors_ordered,
                   edgecolor='black', linewidth=1.5, alpha=0.8)

    # Add value labels on bars
    for i, (bar, drop) in enumerate(zip(bars, drops)):
        ax2.text(bar.get_x() + bar.get_width()/2, drop + 0.3,
                f'{drop:.1f}', ha='center', va='bottom',
                fontsize=11, fontweight='bold')

    ax2.set_xticks(range(len(tiers_ordered)))
    ax2.set_xticklabels(tiers_ordered, rotation=0)
    ax2.set_ylabel('Authenticity Drop (Points)', fontsize=13)
    ax2.set_title('(B) Magnitude of Sponsorship Penalty by Tier',
                  fontsize=14, fontweight='bold')
    ax2.grid(True, axis='y', alpha=0.3)
    ax2.set_ylim(0, max(drops) + 2)

    # Add significance marker
    ax2.text(2, drops[2] + 1.5, '***', ha='center', fontsize=16, color='red')
    ax2.text(2, drops[2] + 2.2, 'p < 0.001', ha='center', fontsize=9)

    plt.tight_layout()
    plt.savefig('moderation_effect_final.png', dpi=300, bbox_inches='tight')
    plt.show()

    # ============================================
    # Print Summary Statistics
    # ============================================
    print("\n" + "="*60)
    print("MODERATION EFFECT SUMMARY (Approach B)")
    print("="*60)
    print("\nModel Equation:")
    print("Authenticity = 39.04 - 5.83(Sponsored) + 2.37(Followers) - 4.19(Sponsored Ã— Followers)")
    print("\nInteraction Coefficient: Î² = -4.190 (p < 0.001)")
    print("Interpretation: For every 1 SD increase in followers,")
    print("                the sponsorship penalty increases by 4.2 points\n")

    print("-" * 60)
    print(f"{'Creator Tier':<25} {'Organic':<12} {'Sponsored':<12} {'Drop':<12}")
    print("-" * 60)
    for _, row in pred_df.iterrows():
        print(f"{row['Tier']:<25} {row['Organic']:>10.1f}  {row['Sponsored']:>10.1f}  {row['Drop']:>10.1f}")
    print("-" * 60)

    print("\nðŸ“Š Key Findings:")
    print(f"  â€¢ High-tier creators lose {pred_df.iloc[2]['Drop']:.1f} points of authenticity")
    print(f"  â€¢ Low-tier creators lose only {pred_df.iloc[0]['Drop']:.1f} points")
    print(f"  â€¢ The 'Big Creator Trap' is {pred_df.iloc[2]['Drop'] / pred_df.iloc[0]['Drop']:.1f}Ã— worse for mega-creators")

    return pred_df


def create_empirical_plot(matched_df):
    """
    Create empirical visualization using actual data
    (Complements the model-based predictions)
    """

    # Create follower tiers from actual data
    conditions = [
        matched_df['follower_count'] > 1000000,
        (matched_df['follower_count'] >= 100000) & (matched_df['follower_count'] <= 1000000),
        matched_df['follower_count'] < 100000
    ]
    choices = ['High Tier (>1M)', 'Medium Tier (100k-1M)', 'Low Tier (<100k)']
    matched_df['Creator Tier'] = np.select(conditions, choices, default='Unknown')

    # Create the plot
    plt.figure(figsize=(10, 6))

    tier_order = ['Low Tier (<100k)', 'Medium Tier (100k-1M)', 'High Tier (>1M)']
    custom_palette = {
        'High Tier (>1M)': '#e74c3c',
        'Medium Tier (100k-1M)': '#3498db',
        'Low Tier (<100k)': '#2ecc71'
    }

    sns.pointplot(
        x='is_sponsored',
        y='authenticity_score',
        hue='Creator Tier',
        data=matched_df,
        hue_order=tier_order,
        markers=['^', 's', 'o'],
        linestyles=[':', '--', '-'],
        capsize=0.1,
        palette=custom_palette,
        errorbar='se',
        markersize=10,
        linewidth=2.5
    )

    plt.xticks([0, 1], ['Organic', 'Sponsored'], fontsize=13)
    plt.ylabel('Authenticity Score (Mean Â± SE)', fontsize=13)
    plt.title('Figure 3: Empirical Moderation Effect by Creator Tier',
              fontsize=14, fontweight='bold')
    plt.legend(title='Creator Tier', loc='best', frameon=True)
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('moderation_effect_empirical.png', dpi=300, bbox_inches='tight')
    plt.show()


# ============================================
# EXECUTION
# ============================================

# Generate both visualizations
print("Creating model-based predictions plot...")
pred_summary = create_moderation_figure(df_matched)

print("\n" + "="*60)
print("Creating empirical data plot...")
create_empirical_plot(df_matched)

print("\nâœ… Analysis Complete!")
print("\nFiles saved:")
print("  â€¢ moderation_effect_final.png (Model predictions)")
print("  â€¢ moderation_effect_empirical.png (Actual data)")

